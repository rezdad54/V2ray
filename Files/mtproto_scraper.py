#!/usr/bin/env python3
"""
MTProto Proxy Scraper
Scrapes MTProto proxies from websites and Telegram channels
"""

import requests
import re
import os
import time
from typing import List, Dict, Any
from telegram_scraper import scrape_telegram_channels_sync

# MTProto proxy pattern
MT_PROTO_PATTERN = r'tg:\/\/socks\?[^\s]+|https:\/\/t\.me\/proxy\?[^\s]+'

def scrape_mtproto_websites() -> List[str]:
    """Scrape MTProto proxies from websites"""
    mtproto_proxies = []
    
    # Websites known to host MTProto proxies
    websites = [
        "https://raw.githubusercontent.com/hookzof/socks5_list/master/tg/mtproto.txt",
        "https://raw.githubusercontent.com/almroot/proxy-list/main/mtproto.txt",
        "https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/mtproto.txt",
        "https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all",
    ]
    
    for website in websites:
        try:
            response = requests.get(website, timeout=15)
            if response.status_code == 200:
                content = response.text
                # Extract MTProto proxies using regex
                proxies = re.findall(MT_PROTO_PATTERN, content)
                mtproto_proxies.extend(proxies)
                print(f"Found {len(proxies)} MTProto proxies from {website}")
        except Exception as e:
            print(f"Error scraping {website}: {e}")
    
    return mtproto_proxies

def scrape_mtproto_telegram() -> List[str]:
    """Scrape MTProto proxies from Telegram channels"""
    mtproto_proxies = []
    
    # Telegram channels known to share MTProto proxies
    telegram_channels = [
        "MTProxy",           # General MTProto channel
        "MTProto_Proxy",     # MTProto proxy channel
        "ProxyMTProto",      # Proxy MTProto channel
        "Free_MTProto",      # Free MTProto proxies
        "MTProtoFree",       # Free MTProto
    ]
    
    try:
        # Use existing Telegram scraper
        telegram_messages = scrape_telegram_channels_sync(telegram_channels, limit_per_channel=10)
        
        for message in telegram_messages:
            # Extract MTProto proxies from Telegram messages
            proxies = re.findall(MT_PROTO_PATTERN, message)
            mtproto_proxies.extend(proxies)
        
        print(f"Found {len(mtproto_proxies)} MTProto proxies from Telegram channels")
        
    except Exception as e:
        print(f"Error scraping Telegram channels for MTProto: {e}")
    
    return mtproto_proxies

def filter_unique_mtproto_proxies(proxies: List[str]) -> List[str]:
    """Filter out duplicate MTProto proxies"""
    unique_proxies = []
    seen = set()
    
    for proxy in proxies:
        # Normalize proxy format for comparison
        normalized = proxy.strip()
        if normalized and normalized not in seen:
            unique_proxies.append(normalized)
            seen.add(normalized)
    
    return unique_proxies

def save_mtproto_proxies(proxies: List[str], output_folder: str) -> str:
    """Save MTProto proxies to file and return the file path"""
    output_filename = os.path.join(output_folder, "MTProto_Proxies.txt")
    
    with open(output_filename, "w", encoding="utf-8") as f:
        f.write("# MTProto Proxies\n")
        f.write("# Generated by V2ray Config Bot\n")
        f.write(f"# Total proxies: {len(proxies)}\n")
        f.write(f"# Last updated: {time.strftime('%Y-%m-%d %H:%M:%S UTC')}\n\n")
        
        for i, proxy in enumerate(proxies, 1):
            f.write(f"{proxy}\n")
    
    return output_filename

def scrape_all_mtproto_proxies(output_folder: str) -> Dict[str, Any]:
    """Scrape all MTProto proxies and save to file"""
    print("ðŸ”„ Starting MTProto proxy scraping...")
    
    # Scrape from websites
    website_proxies = scrape_mtproto_websites()
    
    # Scrape from Telegram channels
    telegram_proxies = scrape_mtproto_telegram()
    
    # Combine all proxies
    all_proxies = website_proxies + telegram_proxies
    
    # Filter duplicates
    unique_proxies = filter_unique_mtproto_proxies(all_proxies)
    
    print(f"ðŸ“Š Found {len(unique_proxies)} unique MTProto proxies")
    
    # Save to file
    output_file = save_mtproto_proxies(unique_proxies, output_folder)
    
    return {
        "total_proxies": len(unique_proxies),
        "website_proxies": len(website_proxies),
        "telegram_proxies": len(telegram_proxies),
        "output_file": output_file,
        "proxies": unique_proxies
    }

if __name__ == "__main__":
    # Test the scraper
    output_folder = os.path.join(os.path.dirname(__file__), "..")
    results = scrape_all_mtproto_proxies(output_folder)
    print(f"âœ… MTProto scraping completed: {results['total_proxies']} proxies saved to {results['output_file']}")